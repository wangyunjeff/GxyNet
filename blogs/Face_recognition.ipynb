{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1: Identify single & Multiple faces in an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Face recognition\n",
    "\n",
    "import cv2\n",
    "import face_recognition\n",
    "\n",
    "image = face_recognition.load_image_file(\"rm.jpg\")\n",
    "face_locations = face_recognition.face_locations(image)\n",
    "image=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "print(face_locations)\n",
    "\n",
    "for i in range(len(face_locations)):\n",
    "    image=cv2.rectangle(image,(face_locations[i][1],face_locations[i][0]),(face_locations[i][3],face_locations[i][2]),(255,0,255),2)\n",
    "\n",
    "cv2.imshow('Output',image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2: Find / Search an image within image gallery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#MATCH given image with a collection of images\n",
    "# import the libraries\n",
    "import os\n",
    "import face_recognition\n",
    "\n",
    "# make a list of all the available images\n",
    "images = os.listdir('.\\celebrities')\n",
    "print(images)\n",
    "\n",
    "image_to_be_matched=face_recognition.load_image_file('.\\Test2.jpeg')\n",
    "#Convert target image to feature vector\n",
    "image_to_be_matched_encoded=face_recognition.face_encodings(image_to_be_matched)[0]\n",
    "\n",
    "# iterate over each image\n",
    "for image in images:\n",
    "    # load the image\n",
    "    current_image = face_recognition.load_image_file('.\\celebrities\\\\' + image)\n",
    "\n",
    "    # encode the loaded image into a feature vector\n",
    "    current_image_encoded = face_recognition.face_encodings(current_image)[0]\n",
    "\n",
    "    # match your image with the image and check if it matches\n",
    "    result = face_recognition.compare_faces(\n",
    "        [image_to_be_matched_encoded], current_image_encoded)\n",
    "\n",
    "    # check if it was a match\n",
    "    if result[0] == True:\n",
    "        print(\"Matched: \" + image)\n",
    "    else:\n",
    "        print(\"Not matched: \" + image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3: Facial feature detection /                                                              Facial landmark detection /                                                          Facial keypoint detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'chin': [(286, 90), (283, 105), (282, 119), (282, 135), (283, 152), (288, 169), (298, 183), (310, 194), (325, 200), (342, 199), (359, 193), (373, 183), (384, 169), (391, 153), (396, 137), (400, 120), (403, 103)], 'left_eyebrow': [(293, 78), (299, 71), (308, 69), (318, 72), (326, 77)], 'right_eyebrow': [(343, 79), (355, 76), (367, 76), (378, 79), (386, 88)], 'nose_bridge': [(333, 87), (332, 95), (330, 103), (328, 112)], 'nose_tip': [(318, 120), (322, 123), (327, 125), (334, 124), (340, 124)], 'left_eye': [(302, 87), (308, 83), (316, 84), (321, 90), (314, 91), (307, 90)], 'right_eye': [(350, 93), (358, 88), (366, 90), (372, 95), (365, 96), (357, 95)], 'top_lip': [(308, 149), (313, 140), (322, 136), (328, 138), (336, 138), (347, 143), (355, 155), (352, 155), (335, 142), (328, 141), (321, 140), (311, 150)], 'bottom_lip': [(355, 155), (346, 168), (335, 173), (327, 172), (320, 171), (312, 164), (308, 149), (311, 150), (321, 163), (328, 165), (335, 165), (352, 155)]}] \n",
      "\n",
      "\n",
      "chin\n",
      "left_eyebrow\n",
      "right_eyebrow\n",
      "nose_bridge\n",
      "nose_tip\n",
      "left_eye\n",
      "right_eye\n",
      "top_lip\n",
      "bottom_lip\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "image = face_recognition.load_image_file(\"ronaldo.jpg\")\n",
    "image=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "face_landmarks_list = face_recognition.face_landmarks(image)\n",
    "print(face_landmarks_list,\"\\n\\n\")\n",
    "\n",
    "for feature in face_landmarks_list[0]:\n",
    "    print(feature)\n",
    "    for x in face_landmarks_list[0][feature]:\n",
    "        cv2.circle(image,x, 1, (0,255,0), 2)\n",
    "\n",
    "cv2.imshow('Output',image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'chin': [(303, 79), (304, 88), (306, 97), (309, 107), (312, 116), (316, 125), (322, 134), (329, 141), (338, 143), (349, 141), (359, 136), (368, 128), (374, 119), (378, 108), (380, 97), (380, 86), (380, 75)], 'left_eyebrow': [(303, 71), (306, 66), (312, 64), (318, 66), (324, 68)], 'right_eyebrow': [(338, 67), (345, 64), (352, 62), (360, 63), (367, 67)], 'nose_bridge': [(331, 75), (331, 81), (331, 88), (331, 95)], 'nose_tip': [(327, 100), (330, 101), (333, 102), (337, 100), (340, 99)], 'left_eye': [(311, 77), (314, 73), (319, 73), (324, 77), (319, 79), (314, 79)], 'right_eye': [(344, 76), (348, 72), (354, 72), (358, 75), (354, 77), (349, 77)], 'top_lip': [(322, 114), (326, 111), (331, 109), (335, 110), (339, 109), (346, 109), (354, 110), (352, 111), (340, 111), (335, 112), (331, 112), (324, 114)], 'bottom_lip': [(354, 110), (348, 118), (341, 121), (336, 122), (332, 122), (327, 120), (322, 114), (324, 114), (331, 117), (335, 117), (340, 116), (352, 111)]}, {'chin': [(180, 148), (179, 157), (179, 167), (180, 177), (182, 187), (186, 197), (191, 206), (198, 213), (207, 216), (217, 215), (227, 211), (236, 204), (242, 196), (247, 186), (250, 176), (252, 165), (253, 155)], 'left_eyebrow': [(184, 144), (187, 137), (194, 135), (201, 136), (208, 138)], 'right_eyebrow': [(219, 140), (226, 138), (234, 139), (241, 143), (244, 150)], 'nose_bridge': [(212, 146), (211, 152), (210, 159), (209, 165)], 'nose_tip': [(202, 170), (205, 171), (209, 173), (213, 172), (218, 171)], 'left_eye': [(192, 147), (195, 145), (200, 145), (204, 149), (200, 150), (195, 149)], 'right_eye': [(222, 151), (226, 148), (231, 149), (235, 152), (231, 153), (226, 153)], 'top_lip': [(197, 184), (202, 182), (206, 182), (209, 183), (213, 183), (218, 185), (223, 187), (221, 187), (213, 185), (209, 185), (206, 184), (199, 184)], 'bottom_lip': [(223, 187), (218, 191), (213, 192), (208, 191), (205, 190), (201, 188), (197, 184), (199, 184), (205, 186), (209, 187), (213, 187), (221, 187)]}] \n",
      "\n",
      "\n",
      "FEATURE is  chin\n",
      "FEATURE is  left_eyebrow\n",
      "FEATURE is  right_eyebrow\n",
      "FEATURE is  nose_bridge\n",
      "FEATURE is  nose_tip\n",
      "FEATURE is  left_eye\n",
      "FEATURE is  right_eye\n",
      "FEATURE is  top_lip\n",
      "FEATURE is  bottom_lip\n",
      "FEATURE is  chin\n",
      "FEATURE is  left_eyebrow\n",
      "FEATURE is  right_eyebrow\n",
      "FEATURE is  nose_bridge\n",
      "FEATURE is  nose_tip\n",
      "FEATURE is  left_eye\n",
      "FEATURE is  right_eye\n",
      "FEATURE is  top_lip\n",
      "FEATURE is  bottom_lip\n",
      "Ran 18 times\n",
      "chin\n",
      "left_eyebrow\n",
      "right_eyebrow\n",
      "nose_bridge\n",
      "nose_tip\n",
      "left_eye\n",
      "right_eye\n",
      "top_lip\n",
      "bottom_lip\n",
      "9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "image = face_recognition.load_image_file(\"rm.jpg\")\n",
    "image=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "face_landmarks_list = face_recognition.face_landmarks(image)\n",
    "print(face_landmarks_list,\"\\n\\n\")\n",
    "#print(len(face_landmarks_list[0]['chin']))\n",
    "\n",
    "features_dict = dict()\n",
    "\n",
    "count=0\n",
    "for i in range(0,len(face_landmarks_list)):\n",
    "    for feature in face_landmarks_list[0]:\n",
    "        count+=1\n",
    "        print(\"FEATURE is \",feature)\n",
    "        if feature in features_dict:\n",
    "            # append the new number to the existing array at this slot\n",
    "            #print(\"Appending...\",face_landmarks_list[0][feature])\n",
    "            for j in range(0,len(face_landmarks_list[i][feature])):\n",
    "                features_dict[feature].append(face_landmarks_list[i][feature][j])\n",
    "        else:\n",
    "            # create a new array in this slot\n",
    "            features_dict[feature] = face_landmarks_list[i][feature]\n",
    "\n",
    "print(\"Ran\",count,\"times\")\n",
    "\n",
    "count=0\n",
    "for feature in features_dict:\n",
    "    print(feature)\n",
    "    count+=1\n",
    "    for x in features_dict[feature]:\n",
    "        #print('X is ',x)\n",
    "        #print(\"Len of X is \",len(x))\n",
    "        #if(len(x)==2):\n",
    "        cv2.circle(image,x, 1, (0,255,0), 2)\n",
    "\n",
    "print(count)\n",
    "cv2.imshow('Output',image)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4: Find all the faces in an image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(46, 374, 136, 285), (126, 255, 216, 165)]\n",
      "I found 2 face(s) in this photograph.\n",
      "A face is located at pixel location Top: 46, Left: 285, Bottom: 136, Right: 374\n",
      "A face is located at pixel location Top: 126, Left: 165, Bottom: 216, Right: 255\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import face_recognition\n",
    "\n",
    "# Load the jpg file into a numpy array\n",
    "image = face_recognition.load_image_file(\"rm.jpg\")\n",
    "\n",
    "# Find all the faces in the image using the default HOG-based model.\n",
    "face_locations = face_recognition.face_locations(image)\n",
    "print(face_locations)\n",
    "print(\"I found {} face(s) in this photograph.\".format(len(face_locations)))\n",
    "\n",
    "for face_location in face_locations:\n",
    "\n",
    "    # Print the location of each face in this image\n",
    "    top, right, bottom, left = face_location\n",
    "    print(\"A face is located at pixel location Top: {}, Left: {}, Bottom: {}, Right: {}\".format(top, left, bottom, right))\n",
    "\n",
    "    # You can access the actual face itself like this:\n",
    "    face_image = image[top:bottom, left:right]\n",
    "    pil_image = Image.fromarray(face_image)\n",
    "    pil_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I found 2 face(s) in this photograph.\n",
      "A face is located at pixel location Top: 124, Left: 164, Bottom: 203, Right: 243\n",
      "A face is located at pixel location Top: 52, Left: 300, Bottom: 131, Right: 379\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import face_recognition\n",
    "\n",
    "# Load the jpg file into a numpy array\n",
    "image = face_recognition.load_image_file(\"rm.jpg\")\n",
    "\n",
    "# Find all the faces in the image using a pre-trained convolutional neural network.\n",
    "# This method is more accurate than the default HOG model, but it's slower\n",
    "# unless you have an nvidia GPU and dlib compiled with CUDA extensions. But if you do,\n",
    "# this will use GPU acceleration and perform well.\n",
    "# See also: find_faces_in_picture.py\n",
    "face_locations = face_recognition.face_locations(image, number_of_times_to_upsample=0, model=\"cnn\")\n",
    "\n",
    "print(\"I found {} face(s) in this photograph.\".format(len(face_locations)))\n",
    "\n",
    "for face_location in face_locations:\n",
    "\n",
    "    # Print the location of each face in this image\n",
    "    top, right, bottom, left = face_location\n",
    "    print(\"A face is located at pixel location Top: {}, Left: {}, Bottom: {}, Right: {}\".format(top, left, bottom, right))\n",
    "\n",
    "    # You can access the actual face itself like this:\n",
    "    face_image = image[top:bottom, left:right]\n",
    "    pil_image = Image.fromarray(face_image)\n",
    "    pil_image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5: Digital Makeup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import face_recognition\n",
    "\n",
    "# Load the jpg file into a numpy array\n",
    "image = face_recognition.load_image_file(\"ronaldo.jpg\")\n",
    "\n",
    "# Find all facial features in all the faces in the image\n",
    "face_landmarks_list = face_recognition.face_landmarks(image)\n",
    "\n",
    "for face_landmarks in face_landmarks_list:\n",
    "    pil_image = Image.fromarray(image)\n",
    "    d = ImageDraw.Draw(pil_image, 'RGBA')\n",
    "\n",
    "    # Make the eyebrows into a nightmare\n",
    "    d.polygon(face_landmarks['left_eyebrow'], fill=(68, 54, 39, 128))\n",
    "    d.polygon(face_landmarks['right_eyebrow'], fill=(68, 54, 39, 128))\n",
    "    d.line(face_landmarks['left_eyebrow'], fill=(68, 54, 39, 150), width=5)\n",
    "    d.line(face_landmarks['right_eyebrow'], fill=(68, 54, 39, 150), width=5)\n",
    "\n",
    "    # Gloss the lips\n",
    "    d.polygon(face_landmarks['top_lip'], fill=(150, 0, 0, 128))\n",
    "    d.polygon(face_landmarks['bottom_lip'], fill=(150, 0, 0, 128))\n",
    "    d.line(face_landmarks['top_lip'], fill=(150, 0, 0, 64), width=8)\n",
    "    d.line(face_landmarks['bottom_lip'], fill=(150, 0, 0, 64), width=8)\n",
    "\n",
    "    # Sparkle the eyes\n",
    "    d.polygon(face_landmarks['left_eye'], fill=(255, 255, 255, 30))\n",
    "    d.polygon(face_landmarks['right_eye'], fill=(255, 255, 255, 30))\n",
    "\n",
    "    # Apply some eyeliner\n",
    "    d.line(face_landmarks['left_eye'] + [face_landmarks['left_eye'][0]], fill=(0, 0, 0, 110), width=6)\n",
    "    d.line(face_landmarks['right_eye'] + [face_landmarks['right_eye'][0]], fill=(0, 0, 0, 110), width=6)\n",
    "\n",
    "    pil_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
